{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (53.926, 63.62]\n",
      "1    (53.926, 63.62]\n",
      "2    (53.926, 63.62]\n",
      "3    (53.926, 63.62]\n",
      "4    (53.926, 63.62]\n",
      "Name: Close_Discretized, dtype: category\n",
      "Categories (5, interval[float64, right]): [(15.102, 24.844] < (24.844, 34.538] < (34.538, 44.232] < (44.232, 53.926] < (53.926, 63.62]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"./data/msft.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Apply equal width discretization to the \"Close\" column with 5 bins\n",
    "num_bins = 5\n",
    "df['Close_Discretized'] = pd.cut(df['Close'], bins=num_bins)\n",
    "\n",
    "# Display the first 5 discretized values\n",
    "print(df['Close_Discretized'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (44.4, 63.62]\n",
      "1    (44.4, 63.62]\n",
      "2    (44.4, 63.62]\n",
      "3    (44.4, 63.62]\n",
      "4    (44.4, 63.62]\n",
      "Name: Close_Discretized, dtype: category\n",
      "Categories (5, interval[float64, right]): [(15.149000000000001, 25.89] < (25.89, 28.678] < (28.678, 31.854] < (31.854, 44.4] < (44.4, 63.62]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate quantiles for equal frequency discretization\n",
    "quantiles = pd.qcut(df['Close'], q=[0, 0.2, 0.4, 0.6, 0.8, 1.0], duplicates='drop')\n",
    "\n",
    "# Apply the quantiles to create the discretized column\n",
    "df['Close_Discretized'] = pd.cut(df['Close'], bins=quantiles.cat.categories)\n",
    "\n",
    "# Display the first 5 discretized values\n",
    "print(df['Close_Discretized'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: circularity\n",
      "Discretized Ranges: <= 50.5, > 50.5\n",
      "Final Entropy: 0.9123564854451003\n",
      "\n",
      "Feature: compactness\n",
      "Discretized Ranges: <= 98.5, > 98.5\n",
      "Final Entropy: 0.9006384628775929\n",
      "\n",
      "Feature: distance_circularity\n",
      "Discretized Ranges: <= 92.5, > 92.5\n",
      "Final Entropy: 0.9225019096999798\n",
      "\n",
      "Feature: elongatedness\n",
      "Discretized Ranges: <= 46.5, > 46.5\n",
      "Final Entropy: 0.695108797965016\n",
      "\n",
      "Feature: gyrationradius\n",
      "Discretized Ranges: <= 188.5, > 188.5\n",
      "Final Entropy: 0.9027996319846472\n",
      "\n",
      "Feature: hollows_ratio\n",
      "Discretized Ranges: <= 189.5, > 189.5\n",
      "Final Entropy: 0.9039392810777032\n",
      "\n",
      "Feature: lengthrectangular\n",
      "Discretized Ranges: <= 167.5, > 167.5\n",
      "Final Entropy: 0.9744644319183258\n",
      "\n",
      "Feature: majorkurtosis\n",
      "Discretized Ranges: <= 181.5, > 181.5\n",
      "Final Entropy: 0.928548210630629\n",
      "\n",
      "Feature: majorskewness\n",
      "Discretized Ranges: <= 64.5, > 64.5\n",
      "Final Entropy: 0.9201571722393916\n",
      "\n",
      "Feature: majorvariance\n",
      "Discretized Ranges: <= 165.5, > 165.5\n",
      "Final Entropy: 0.718834477909226\n",
      "\n",
      "Feature: max_length_aspect_ratio\n",
      "Discretized Ranges: <= 8.5, > 8.5\n",
      "Final Entropy: 0.7207115439556998\n",
      "\n",
      "Feature: minorkurtosis\n",
      "Discretized Ranges: <= 29.5, > 29.5\n",
      "Final Entropy: 0.9939988571504409\n",
      "\n",
      "Feature: minorskewness\n",
      "Discretized Ranges: <= 11.5, > 11.5\n",
      "Final Entropy: 0.9499553593590914\n",
      "\n",
      "Feature: minorvariance\n",
      "Discretized Ranges: <= 297.5, > 297.5\n",
      "Final Entropy: 0.685004743409071\n",
      "\n",
      "Feature: pr_axis_aspect_ratio\n",
      "Discretized Ranges: <= 68.5, > 68.5\n",
      "Final Entropy: 0.9244601389764059\n",
      "\n",
      "Feature: pr_axisrectangular\n",
      "Discretized Ranges: <= 18.5, > 18.5\n",
      "Final Entropy: 0.7324728582840851\n",
      "\n",
      "Feature: radius_ratio\n",
      "Discretized Ranges: <= 176.5, > 176.5\n",
      "Final Entropy: 0.8349817494892466\n",
      "\n",
      "Feature: scatter_ratio\n",
      "Discretized Ranges: <= 140.5, > 140.5\n",
      "Final Entropy: 0.685004743409071\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"./data/vehicles.csv\"\n",
    "# Load the dataset skipping the first row (header)\n",
    "vehicles_df = pd.read_csv(file_path, header=0)\n",
    "\n",
    "# Filter only \"van\" and \"bus\" classes\n",
    "vehicles_df = vehicles_df[(vehicles_df[\"class\"] == \"van\") | (vehicles_df[\"class\"] == \"bus\")]\n",
    "vehicles_df[\"class\"] = vehicles_df[\"class\"].replace([\"van\"], 0)\n",
    "vehicles_df[\"class\"] = vehicles_df[\"class\"].replace([\"bus\"], 1)\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    unique_labels, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def find_best_split(df, feature, class_column='class'):\n",
    "    unique_values = df[feature].unique()\n",
    "    unique_values.sort()\n",
    "\n",
    "    best_split_point = None\n",
    "    best_entropy = float('inf')\n",
    "\n",
    "    for i in range(len(unique_values) - 1):\n",
    "        split_point = (unique_values[i] + unique_values[i + 1]) / 2\n",
    "        left_mask = df[feature] <= split_point\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        left_entropy = calculate_entropy(df[left_mask][class_column])\n",
    "        right_entropy = calculate_entropy(df[right_mask][class_column])\n",
    "\n",
    "        total_entropy = (len(df[left_mask]) * left_entropy + len(df[right_mask]) * right_entropy) / len(df)\n",
    "\n",
    "        if total_entropy < best_entropy:\n",
    "            best_entropy = total_entropy\n",
    "            best_split_point = split_point\n",
    "\n",
    "    return best_split_point, best_entropy\n",
    "\n",
    "def discretize_recursive(df, features):\n",
    "    for feature in features:\n",
    "        print(f\"\\nFeature: {feature}\")\n",
    "        split_point, entropy = find_best_split(df, feature)\n",
    "\n",
    "        print(f\"Discretized Ranges: <= {split_point}, > {split_point}\")\n",
    "        print(f\"Final Entropy: {entropy}\")\n",
    "\n",
    "        df[feature] = np.where(df[feature] <= split_point, f'<= {split_point}', f'> {split_point}')\n",
    "\n",
    "# Specify features to discretize (excluding the 'class' column)\n",
    "features_to_discretize = vehicles_df.columns.difference(['class'])\n",
    "\n",
    "# Perform recursive discretization\n",
    "discretize_recursive(vehicles_df, features_to_discretize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by Mean Absolute Deviation:\n",
      "minorvariance              94.5\n",
      "radius_ratio               27.0\n",
      "gyrationradius             24.5\n",
      "scatter_ratio              20.0\n",
      "majorvariance              19.5\n",
      "distance_circularity       12.0\n",
      "lengthrectangular          11.0\n",
      "minorkurtosis               6.0\n",
      "compactness                 6.0\n",
      "elongatedness               6.0\n",
      "circularity                 5.0\n",
      "hollows_ratio               5.0\n",
      "majorskewness               4.5\n",
      "minorskewness               4.0\n",
      "pr_axis_aspect_ratio        4.0\n",
      "majorkurtosis               4.0\n",
      "pr_axisrectangular          2.0\n",
      "max_length_aspect_ratio     2.0\n",
      "class                       1.0\n",
      "dtype: float64\n",
      "\n",
      "Features to be removed based on correlation above 0.9:\n",
      "['scatter_ratio', 'elongatedness', 'pr_axisrectangular', 'lengthrectangular', 'majorvariance', 'minorvariance', 'gyrationradius']\n",
      "\n",
      "DataFrame after removing highly correlated features:\n",
      "     compactness  circularity  distance_circularity  radius_ratio  \\\n",
      "0             95           43                    96           202   \n",
      "1             96           52                   104           222   \n",
      "2            107           52                   101           218   \n",
      "3             97           37                    78           181   \n",
      "4             96           54                   104           175   \n",
      "..           ...          ...                   ...           ...   \n",
      "841           88           40                    55           114   \n",
      "842           86           39                    62           129   \n",
      "843           94           47                    85           333   \n",
      "844           86           40                    66           139   \n",
      "845           92           38                    60           130   \n",
      "\n",
      "     pr_axis_aspect_ratio  max_length_aspect_ratio  majorskewness  \\\n",
      "0                      65                       10             71   \n",
      "1                      67                        9             67   \n",
      "2                      64                       11             65   \n",
      "3                      62                        8             62   \n",
      "4                      58                       10             75   \n",
      "..                    ...                      ...            ...   \n",
      "841                    53                        7             87   \n",
      "842                    59                        6             64   \n",
      "843                   138                       49            135   \n",
      "844                    59                        7             63   \n",
      "845                    62                        5             72   \n",
      "\n",
      "     minorskewness  minorkurtosis  majorkurtosis  hollows_ratio  class  \n",
      "0                6             27            190            197      3  \n",
      "1               12             20            192            201      3  \n",
      "2               17              2            197            206      3  \n",
      "3                2             28            203            211      3  \n",
      "4               13             23            186            194      3  \n",
      "..             ...            ...            ...            ...    ...  \n",
      "841              0              7            176            183      0  \n",
      "842              7              9            199            204      0  \n",
      "843             12              9            188            196      0  \n",
      "844              7             11            202            208      0  \n",
      "845             14              5            190            194      0  \n",
      "\n",
      "[846 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_absolute_deviation(df):\n",
    "    # Convert class labels to numeric\n",
    "    class_mapping = {\"van\": 0, \"bus\": 1, \"saab\": 2, \"opel\": 3}\n",
    "    df[\"class\"] = df[\"class\"].map(class_mapping)\n",
    "\n",
    "    # Compute Mean Absolute Deviation (MAD) for each feature\n",
    "    mad_values = df.apply(lambda x: (x - x.median()).abs().median())\n",
    "\n",
    "    # Sort features based on MAD in descending order\n",
    "    sorted_features_mad = mad_values.sort_values(ascending=False)\n",
    "\n",
    "    # Print sorted features based on MAD\n",
    "    print(\"Features sorted by Mean Absolute Deviation:\")\n",
    "    print(sorted_features_mad)\n",
    "\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    # Compute correlation matrix\n",
    "    correlation_matrix = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find features with correlation above the threshold\n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "    # Print features to be removed\n",
    "    print(f\"\\nFeatures to be removed based on correlation above {threshold}:\")\n",
    "    print(to_drop)\n",
    "\n",
    "    # Drop highly correlated features\n",
    "    df_filtered = df.drop(columns=to_drop)\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './data/vehicles.csv'\n",
    "vehicles_df = pd.read_csv(file_path)\n",
    "\n",
    "# Compute Mean Absolute Deviation\n",
    "compute_mean_absolute_deviation(vehicles_df)\n",
    "\n",
    "# Remove highly correlated features\n",
    "filtered_df = remove_highly_correlated_features(vehicles_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nDataFrame after removing highly correlated features:\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components:\n",
      "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0  1.544291 -0.806329  0.356535 -1.645952  0.897445  0.556681 -0.060381   \n",
      "1  3.664223 -0.922105  0.059968  0.444837  0.789021 -0.149480 -1.348124   \n",
      "2  3.788722 -1.937588 -0.106526  2.435800  0.418041  0.355490  0.553890   \n",
      "3 -1.062921 -4.028445 -0.120206 -1.940805  0.157198  0.260954  0.542114   \n",
      "4  3.989150  1.178758 -0.898485  0.174144  1.478310 -0.786526 -0.570053   \n",
      "\n",
      "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
      "0  0.575771 -0.026833 -0.057672  0.081963  0.205111 -0.021366  0.104711   \n",
      "1  0.448645  0.113455 -0.314922  0.022146  0.104553  0.132771  0.161079   \n",
      "2  0.226956 -0.053726  0.264556  0.055300  0.028697  0.081891  0.325239   \n",
      "3 -0.443677  0.393767  0.248347 -0.066988 -0.054382 -0.103389  0.009887   \n",
      "4  0.273657  0.531122  0.435342  0.157833  0.097256  0.020937 -0.229531   \n",
      "\n",
      "       PC15      PC16      PC17      PC18  \n",
      "0  0.059293 -0.054826  0.031268 -0.003685  \n",
      "1 -0.099213 -0.257007  0.054623  0.026497  \n",
      "2 -0.106731  0.030836  0.011541 -0.021774  \n",
      "3 -0.050243  0.016550  0.086929 -0.026701  \n",
      "4  0.046987 -0.095539 -0.133092  0.015746  \n",
      "\n",
      "Explained Variance Ratio:\n",
      "[5.23785310e-01 1.67934043e-01 1.05476685e-01 6.56771417e-02\n",
      " 5.05621438e-02 2.96320479e-02 1.97796845e-02 1.22663636e-02\n",
      " 8.78054223e-03 5.07294942e-03 3.49545447e-03 2.43591665e-03\n",
      " 1.94699017e-03 1.18580328e-03 8.88395141e-04 7.16302251e-04\n",
      " 3.44085729e-04 2.01413775e-05]\n",
      "\n",
      "Cumulative Explained Variance:\n",
      "[0.52378531 0.69171935 0.79719604 0.86287318 0.91343532 0.94306737\n",
      " 0.96284706 0.97511342 0.98389396 0.98896691 0.99246237 0.99489828\n",
      " 0.99684527 0.99803108 0.99891947 0.99963577 0.99997986 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vehicles_df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert class labels to numeric\n",
    "class_mapping = {\"van\": 0, \"bus\": 1, \"saab\": 2, \"opel\": 3}\n",
    "vehicles_df[\"class\"] = vehicles_df[\"class\"].map(class_mapping)\n",
    "\n",
    "# Separate features and labels\n",
    "X = vehicles_df.drop(columns=['class'])\n",
    "y = vehicles_df['class']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(X_standardized)\n",
    "\n",
    "# Create a DataFrame with principal components\n",
    "pc_columns = [f'PC{i+1}' for i in range(principal_components.shape[1])]\n",
    "pc_df = pd.DataFrame(data=principal_components, columns=pc_columns)\n",
    "\n",
    "# Display the principal components DataFrame\n",
    "print(\"Principal Components:\")\n",
    "print(pc_df.head())\n",
    "\n",
    "# Percentage of variance explained by each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "print(cumulative_explained_variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
